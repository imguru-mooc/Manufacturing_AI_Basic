{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaYfUtQo9zA8"
      },
      "source": [
        "# ğŸ­ ì‹¤ìŠµ 1: ì œì¡° ë°ì´í„° ë§µ & ë¹„ì „ ê²€ì‚¬ ì…ë¬¸\n",
        "\n",
        "**ì†Œìš”ì‹œê°„: 2ì‹œê°„ | ë‚œì´ë„: â˜…â˜†â˜†â˜†â˜† (ì…ë¬¸)**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
        "\n",
        "- ì œì¡° í˜„ì¥ì˜ OT/IT êµ¬ì¡°(PLC, SCADA, MES)ë¥¼ ì´í•´í•©ë‹ˆë‹¤\n",
        "- ì œì¡° ë°ì´í„° ìœ í˜•(ì´ë¯¸ì§€, ì‹œê³„ì—´, í…ìŠ¤íŠ¸)ì„ êµ¬ë¶„í•˜ê³  í™œìš©í•©ë‹ˆë‹¤\n",
        "- ì „ì´í•™ìŠµ ê¸°ë°˜ OK/NG ë¶„ë¥˜ ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•©ë‹ˆë‹¤\n",
        "- **YOLOv8ì„ í™œìš©í•œ ê²°í•¨ íƒì§€(Object Detection)ë¥¼ ì‹¤ìŠµí•©ë‹ˆë‹¤**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ ì‚¬ì „ ì¤€ë¹„\n",
        "\n",
        "- Google Colab ê³„ì • (ë¬´ë£Œ GPU ì‚¬ìš©)\n",
        "- ê¸°ë³¸ Python ë¬¸ë²• ì´í•´\n",
        "- ë”¥ëŸ¬ë‹ ê¸°ì´ˆ ê°œë… (CNNì´ ë¬´ì—‡ì¸ì§€ ì •ë„)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrsr3jaH9zA9"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: ì œì¡° í˜„ì¥ OT/IT êµ¬ì¡° ì´í•´ (30ë¶„)\n",
        "\n",
        "## 1.1 ì œì¡° ì‹œìŠ¤í…œ ê³„ì¸µ êµ¬ì¡°\n",
        "\n",
        "ì œì¡° í˜„ì¥ì€ í¬ê²Œ ì„¸ ê°€ì§€ ê³„ì¸µìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:\n",
        "\n",
        "| ê³„ì¸µ | ì‹œìŠ¤í…œ | ì—­í•  |\n",
        "|------|--------|------|\n",
        "| **í˜„ì¥ ê³„ì¸µ** | PLC (Programmable Logic Controller) | ì„¼ì„œ/ì•¡ì¶”ì—ì´í„° ì§ì ‘ ì œì–´ |\n",
        "| **ê°ì‹œ ê³„ì¸µ** | SCADA (Supervisory Control) | ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì œì–´ |\n",
        "| **ê´€ë¦¬ ê³„ì¸µ** | MES (Manufacturing Execution) | ìƒì‚° ê³„íš, í’ˆì§ˆ ê´€ë¦¬, ì¶”ì  |\n",
        "\n",
        "## 1.2 ì œì¡° ë°ì´í„° ìœ í˜•\n",
        "\n",
        "| ë°ì´í„° ìœ í˜• | ì˜ˆì‹œ | AI í™œìš© |\n",
        "|-------------|------|--------|\n",
        "| **ì´ë¯¸ì§€** | ì¹´ë©”ë¼ ì´¬ì˜ ì œí’ˆ ì‚¬ì§„ | ë¹„ì „ ê²€ì‚¬, ê²°í•¨ íƒì§€ |\n",
        "| **ì‹œê³„ì—´** | ì˜¨ë„, ì••ë ¥, ì§„ë™ ì„¼ì„œ ë°ì´í„° | ì˜ˆì§€ë³´ì „, ì´ìƒ íƒì§€ |\n",
        "| **í…ìŠ¤íŠ¸/í…Œì´ë¸”** | ì‘ì—…ì¼ì§€, í’ˆì§ˆ ê¸°ë¡ | ê³µì • ìµœì í™”, ìˆ˜ìœ¨ ì˜ˆì¸¡ |\n",
        "\n",
        "## 1.3 ë¹„ì „ ê²€ì‚¬ ë°©ì‹ ë¹„êµ\n",
        "\n",
        "| ë°©ì‹ | ëª¨ë¸ ì˜ˆì‹œ | ì¶œë ¥ | ì í•©í•œ ìƒí™© |\n",
        "|------|-----------|------|-------------|\n",
        "| **ë¶„ë¥˜ (Classification)** | ResNet, EfficientNet | OK/NG ë¼ë²¨ | ì „ì²´ ì œí’ˆì˜ ì–‘/ë¶ˆ íŒì • |\n",
        "| **ê°ì²´ íƒì§€ (Object Detection)** | YOLO, Faster R-CNN | ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ | ê²°í•¨ ìœ„ì¹˜ ë° ì¢…ë¥˜ íŠ¹ì • |\n",
        "| **ì„¸ê·¸ë©˜í…Œì´ì…˜ (Segmentation)** | U-Net, Mask R-CNN | í”½ì…€ ë‹¨ìœ„ ë§ˆìŠ¤í¬ | ì •ë°€í•œ ê²°í•¨ ì˜ì—­ ì¸¡ì • |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AxYrpQQ9zA9"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2: ì „ì´í•™ìŠµ ê¸°ë°˜ OK/NG ë¶„ë¥˜ ì‹¤ìŠµ (40ë¶„)\n",
        "\n",
        "## 2.1 í™˜ê²½ ì„¤ì •\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###í•œê¸€ ê¹¨ì§ ë°©ì§€"
      ],
      "metadata": {
        "id": "UNUPCbTe91uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y fonts-nanum*\n",
        "!rm -rf /root/.cache/matplotlib/* # í°íŠ¸ ìºì‹œ ì¬ì„¤ì •\n",
        "# ëŸ°íƒ€ì„ ë‹¤ì‹œ ì‹œì‘"
      ],
      "metadata": {
        "id": "uKdH6mcE950t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "#\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_name = mpl.font_manager.FontProperties(fname=path).get_name()\n",
        "plt.rcParams['font.family'] = font_name"
      ],
      "metadata": {
        "id": "wHEUzh2m-BN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSF6zk8b9zA9"
      },
      "outputs": [],
      "source": [
        "# Step 1: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
        "!pip install -q torch torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "\n",
        "print(f'PyTorch ë²„ì „: {torch.__version__}')\n",
        "print(f'GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU ì´ë¦„: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6hQylXw9zA9"
      },
      "source": [
        "## 2.2 ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„\n",
        "\n",
        "ì‹¤ì œ ì‚°ì—… í™˜ê²½ì—ì„œëŠ” MVTec AD ê°™ì€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
        "ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ì‹¤ìŠµí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_lkuZHK9zA9"
      },
      "outputs": [],
      "source": [
        "# Step 2: ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° êµ¬ì„±\n",
        "!mkdir -p data/train/OK data/train/NG data/val/OK data/val/NG\n",
        "\n",
        "def create_sample_images():\n",
        "    '''OK: ê· ì¼í•œ í‘œë©´, NG: ìŠ¤í¬ë˜ì¹˜ê°€ ìˆëŠ” í‘œë©´'''\n",
        "    for split in ['train', 'val']:\n",
        "        n = 50 if split == 'train' else 10\n",
        "        for i in range(n):\n",
        "            # OK ì´ë¯¸ì§€: ê¹¨ë—í•œ íšŒìƒ‰ ë°°ê²½\n",
        "            ok_img = np.ones((224, 224, 3), dtype=np.uint8) * 180\n",
        "            ok_img = ok_img + np.random.randint(-10, 10, ok_img.shape).astype(np.uint8)\n",
        "            Image.fromarray(ok_img).save(f'data/{split}/OK/{i}.png')\n",
        "\n",
        "            # NG ì´ë¯¸ì§€: ìŠ¤í¬ë˜ì¹˜ ì¶”ê°€\n",
        "            ng_img = ok_img.copy()\n",
        "            for _ in range(random.randint(1, 3)):\n",
        "                x1, y1 = random.randint(0, 200), random.randint(0, 200)\n",
        "                x2, y2 = x1 + random.randint(10, 50), y1 + random.randint(2, 5)\n",
        "                ng_img[y1:y2, x1:x2] = [50, 50, 50]\n",
        "            Image.fromarray(ng_img).save(f'data/{split}/NG/{i}.png')\n",
        "\n",
        "create_sample_images()\n",
        "print('âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!')\n",
        "print(f'   - í•™ìŠµ ë°ì´í„°: OK {len(os.listdir(\"data/train/OK\"))}ê°œ, NG {len(os.listdir(\"data/train/NG\"))}ê°œ')\n",
        "print(f'   - ê²€ì¦ ë°ì´í„°: OK {len(os.listdir(\"data/val/OK\"))}ê°œ, NG {len(os.listdir(\"data/val/NG\"))}ê°œ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uWyDs1E9zA-"
      },
      "outputs": [],
      "source": [
        "# ìƒì„±ëœ ì´ë¯¸ì§€ ìƒ˜í”Œ í™•ì¸\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "\n",
        "for i, ax in enumerate(axes[0]):\n",
        "    img = Image.open(f'data/train/OK/{i}.png')\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f'OK Sample {i+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "for i, ax in enumerate(axes[1]):\n",
        "    img = Image.open(f'data/train/NG/{i}.png')\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f'NG Sample {i+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('OK vs NG ìƒ˜í”Œ ì´ë¯¸ì§€', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDevcN7F9zA-"
      },
      "source": [
        "## 2.3 ì „ì´í•™ìŠµ ëª¨ë¸ êµ¬í˜„\n",
        "\n",
        "ResNet18ì„ ê¸°ë°˜ìœ¼ë¡œ 2-class ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
        "\n",
        "### ì „ì´í•™ìŠµ(Transfer Learning)ì´ë€?\n",
        "- ëŒ€ê·œëª¨ ë°ì´í„°ì…‹(ImageNet)ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ê°€ì ¸ì™€ì„œ\n",
        "- ìš°ë¦¬ ë¬¸ì œ(OK/NG ë¶„ë¥˜)ì— ë§ê²Œ ë¯¸ì„¸ ì¡°ì •(Fine-tuning)í•˜ëŠ” ê¸°ë²•\n",
        "- ì ì€ ë°ì´í„°ë¡œë„ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDE9aQU39zA-"
      },
      "outputs": [],
      "source": [
        "# Step 3: ë°ì´í„° ë¡œë” ì„¤ì •\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = ImageFolder('data/train', transform=transform)\n",
        "val_dataset = ImageFolder('data/val', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(f'âœ… ë°ì´í„° ë¡œë” ì„¤ì • ì™„ë£Œ!')\n",
        "print(f'   - í´ë˜ìŠ¤: {train_dataset.classes}')\n",
        "print(f'   - í´ë˜ìŠ¤ ì¸ë±ìŠ¤: {train_dataset.class_to_idx}')\n",
        "print(f'   - í•™ìŠµ ë°ì´í„°: {len(train_dataset)}ê°œ')\n",
        "print(f'   - ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d82WuK0L9zA-"
      },
      "outputs": [],
      "source": [
        "# Step 4: ì „ì´í•™ìŠµ ëª¨ë¸ ì •ì˜\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}')\n",
        "\n",
        "# ì‚¬ì „í•™ìŠµëœ ResNet18 ë¡œë“œ\n",
        "model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# ë§ˆì§€ë§‰ FC ë ˆì´ì–´ë¥¼ 2-classë¡œ ë³€ê²½ (OK/NG)\n",
        "num_features = model.fc.in_features\n",
        "print(f'ì›ë˜ FC ì…ë ¥ íŠ¹ì„± ìˆ˜: {num_features}')\n",
        "print(f'ì›ë˜ FC ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜: 1000 (ImageNet)')\n",
        "\n",
        "model.fc = nn.Linear(num_features, 2)  # 2ê°œ í´ë˜ìŠ¤ë¡œ ë³€ê²½\n",
        "print(f'ë³€ê²½ëœ FC ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜: 2 (OK/NG)')\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print('\\nâœ… ì „ì´í•™ìŠµ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7JHV69u9zA-"
      },
      "source": [
        "## 2.4 ëª¨ë¸ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YN8g1hv9zA-"
      },
      "outputs": [],
      "source": [
        "# Step 5: í•™ìŠµ ë£¨í”„\n",
        "def train_epoch(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss, correct = 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "    return total_loss / len(loader), correct / len(loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "# í•™ìŠµ ê¸°ë¡ ì €ì¥\n",
        "history = {'loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "# í•™ìŠµ ì‹¤í–‰\n",
        "print('ğŸš€ í•™ìŠµ ì‹œì‘!\\n')\n",
        "for epoch in range(5):\n",
        "    loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    val_acc = evaluate(model, val_loader)\n",
        "\n",
        "    history['loss'].append(loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/5: Loss={loss:.4f}, Train Acc={train_acc:.2%}, Val Acc={val_acc:.2%}')\n",
        "\n",
        "print('\\nâœ… í•™ìŠµ ì™„ë£Œ!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4FyIgAz9zA-"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµ ê³¼ì • ì‹œê°í™”\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss ê·¸ë˜í”„\n",
        "axes[0].plot(history['loss'], 'b-o', label='Training Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Accuracy ê·¸ë˜í”„\n",
        "axes[1].plot(history['train_acc'], 'b-o', label='Train Accuracy')\n",
        "axes[1].plot(history['val_acc'], 'r-o', label='Validation Accuracy')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].set_title('Training & Validation Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vY9sXa49zA-"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: í˜¼ë™í–‰ë ¬ ë° ì„ê³„ê°’ ì¡°ì • ì‹¤ìŠµ (20ë¶„)\n",
        "\n",
        "## 3.1 í˜¼ë™í–‰ë ¬(Confusion Matrix) ì‹œê°í™”\n",
        "\n",
        "### í˜¼ë™í–‰ë ¬ êµ¬ì„±ìš”ì†Œ\n",
        "- **TP (True Positive)**: NGë¥¼ NGë¡œ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡\n",
        "- **TN (True Negative)**: OKë¥¼ OKë¡œ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡\n",
        "- **FP (False Positive)**: OKë¥¼ NGë¡œ ì˜ëª» ì˜ˆì¸¡ (ê³¼ê²€ì¶œ)\n",
        "- **FN (False Negative)**: NGë¥¼ OKë¡œ ì˜ëª» ì˜ˆì¸¡ (ê³¼ê²€ì¶œ ëˆ„ë½) âš ï¸ ê°€ì¥ ìœ„í—˜!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSqWmxhC9zA_"
      },
      "outputs": [],
      "source": [
        "# Step 6: í˜¼ë™í–‰ë ¬ ìƒì„±\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_predictions(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels, all_probs = [], [], []\n",
        "    for images, labels in loader:\n",
        "        outputs = model(images.to(device))\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        all_probs.extend(probs[:, 1].cpu().numpy())  # NG í™•ë¥ \n",
        "        all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
        "\n",
        "preds, labels, probs = get_predictions(model, val_loader)\n",
        "\n",
        "# í˜¼ë™í–‰ë ¬ ì‹œê°í™”\n",
        "cm = confusion_matrix(labels, preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['OK (ì˜ˆì¸¡)', 'NG (ì˜ˆì¸¡)'],\n",
        "            yticklabels=['OK (ì‹¤ì œ)', 'NG (ì‹¤ì œ)'],\n",
        "            annot_kws={'size': 16})\n",
        "plt.xlabel('ì˜ˆì¸¡', fontsize=12)\n",
        "plt.ylabel('ì‹¤ì œ', fontsize=12)\n",
        "plt.title('OK/NG ë¶„ë¥˜ í˜¼ë™í–‰ë ¬', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "print('\\nğŸ“Š ë¶„ë¥˜ ë¦¬í¬íŠ¸:')\n",
        "print(classification_report(labels, preds, target_names=['OK', 'NG']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMKbgpOG9zA_"
      },
      "source": [
        "## 3.2 ì„ê³„ê°’ ì¡°ì •ì˜ ì¤‘ìš”ì„±\n",
        "\n",
        "ì œì¡° í˜„ì¥ì—ì„œëŠ” **NGë¥¼ OKë¡œ íŒì •í•˜ëŠ” ê²ƒ(FN, ê³¼ê²€ì¶œ ëˆ„ë½)**ì´ ì¹˜ëª…ì ì…ë‹ˆë‹¤.  \n",
        "ë¶ˆëŸ‰í’ˆì´ ê³ ê°ì—ê²Œ ì „ë‹¬ë˜ë©´ í° ì†ì‹¤ì´ ë°œìƒí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì„ê³„ê°’ì„ ì¡°ì •í•˜ì—¬ NG ê²€ì¶œìœ¨ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
        "- **ì„ê³„ê°’ ë‚®ì¶¤** â†’ NG ê²€ì¶œìœ¨ â†‘, ì˜¤ê²€ì¶œìœ¨ â†‘\n",
        "- **ì„ê³„ê°’ ë†’ì„** â†’ NG ê²€ì¶œìœ¨ â†“, ì˜¤ê²€ì¶œìœ¨ â†“"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5fyV3iq9zA_"
      },
      "outputs": [],
      "source": [
        "# Step 7: ì„ê³„ê°’ ì¡°ì •\n",
        "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "\n",
        "print('ğŸ“ˆ ì„ê³„ê°’ë³„ ì„±ëŠ¥ ë¹„êµ:\\n')\n",
        "print(f'{\"ì„ê³„ê°’\":^8} | {\"NG ê²€ì¶œìœ¨(Recall)\":^18} | {\"ì˜¤ê²€ì¶œìœ¨(FPR)\":^15} | {\"ì •í™•ë„\":^10}')\n",
        "print('-' * 60)\n",
        "\n",
        "results = []\n",
        "for thresh in thresholds:\n",
        "    adjusted_preds = (probs >= thresh).astype(int)\n",
        "    cm = confusion_matrix(labels, adjusted_preds)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    results.append({'threshold': thresh, 'recall': recall, 'fpr': fpr, 'accuracy': accuracy})\n",
        "    print(f'{thresh:^8.1f} | {recall:^18.2%} | {fpr:^15.2%} | {accuracy:^10.2%}')\n",
        "\n",
        "print('\\nğŸ’¡ ì œì¡° í˜„ì¥ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ NG ê²€ì¶œìœ¨(Recall)ì„ ë†’ì´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDpi954w9zA_"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 4: YOLOv8 ê¸°ë°˜ ê²°í•¨ íƒì§€ ì‹¤ìŠµ (30ë¶„) ğŸ†•\n",
        "\n",
        "## 4.1 YOLOë€?\n",
        "\n",
        "**YOLO (You Only Look Once)**ëŠ” ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.\n",
        "\n",
        "### ë¶„ë¥˜ vs ê°ì²´ íƒì§€\n",
        "\n",
        "| êµ¬ë¶„ | ë¶„ë¥˜ (Classification) | ê°ì²´ íƒì§€ (Object Detection) |\n",
        "|------|----------------------|-----------------------------|\n",
        "| **ì¶œë ¥** | í´ë˜ìŠ¤ ë¼ë²¨ (OK/NG) | ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ |\n",
        "| **ì¥ì ** | ë‹¨ìˆœ, ë¹ ë¦„ | ê²°í•¨ ìœ„ì¹˜ íŠ¹ì • ê°€ëŠ¥ |\n",
        "| **ë‹¨ì ** | ìœ„ì¹˜ ì •ë³´ ì—†ìŒ | ë¼ë²¨ë§ ë¹„ìš© ë†’ìŒ |\n",
        "| **ì ìš©** | ì „ì²´ ì–‘/ë¶ˆ íŒì • | ê²°í•¨ ì¢…ë¥˜ë³„ ìœ„ì¹˜ íŒŒì•… |\n",
        "\n",
        "### YOLOv8 íŠ¹ì§•\n",
        "- Ultralyticsì—ì„œ ê°œë°œí•œ ìµœì‹  YOLO ë²„ì „\n",
        "- ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ Python API\n",
        "- íƒì§€, ì„¸ê·¸ë©˜í…Œì´ì…˜, ë¶„ë¥˜, í¬ì¦ˆ ì¶”ì • ì§€ì›\n",
        "- COCO ë°ì´í„°ì…‹ ê¸°ì¤€ ìµœê³  ìˆ˜ì¤€ ì„±ëŠ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqwLGyta9zA_"
      },
      "outputs": [],
      "source": [
        "# Step 8: YOLOv8 ì„¤ì¹˜\n",
        "!pip install -q ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('âœ… YOLOv8 ì„¤ì¹˜ ì™„ë£Œ!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSoL2Wor9zA_"
      },
      "source": [
        "## 4.2 ê²°í•¨ íƒì§€ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
        "\n",
        "ì‹¤ì œ ì œì¡° í˜„ì¥ì—ì„œëŠ” ë‹¤ì–‘í•œ ê²°í•¨ ìœ í˜•ì´ ìˆìŠµë‹ˆë‹¤:\n",
        "- **Scratch**: ìŠ¤í¬ë˜ì¹˜\n",
        "- **Dent**: ì°Œê·¸ëŸ¬ì§\n",
        "- **Stain**: ì–¼ë£©\n",
        "- **Crack**: ê· ì—´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw7mvDkS9zA_"
      },
      "outputs": [],
      "source": [
        "# Step 9: ê²°í•¨ íƒì§€ìš© ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "!mkdir -p yolo_data/images/train yolo_data/images/val\n",
        "!mkdir -p yolo_data/labels/train yolo_data/labels/val\n",
        "\n",
        "def create_defect_image(img_size=640, defects=None):\n",
        "    '''\n",
        "    ê²°í•¨ì´ ìˆëŠ” ì œí’ˆ ì´ë¯¸ì§€ ìƒì„±\n",
        "    Returns: (ì´ë¯¸ì§€, ë¼ë²¨ ë¦¬ìŠ¤íŠ¸)\n",
        "    ë¼ë²¨ í˜•ì‹: [class_id, x_center, y_center, width, height] (ì •ê·œí™”)\n",
        "    '''\n",
        "    # ë°°ê²½ ì´ë¯¸ì§€ (ê¸ˆì† í‘œë©´ ì‹œë®¬ë ˆì´ì…˜)\n",
        "    img = np.ones((img_size, img_size, 3), dtype=np.uint8) * 180\n",
        "    img = img + np.random.randint(-15, 15, img.shape).astype(np.int16)\n",
        "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    if defects is None:\n",
        "        defects = random.sample(['scratch', 'dent', 'stain', 'crack'],\n",
        "                                k=random.randint(1, 3))\n",
        "\n",
        "    class_map = {'scratch': 0, 'dent': 1, 'stain': 2, 'crack': 3}\n",
        "\n",
        "    for defect in defects:\n",
        "        # ëœë¤ ìœ„ì¹˜ ë° í¬ê¸°\n",
        "        x = random.randint(50, img_size - 100)\n",
        "        y = random.randint(50, img_size - 100)\n",
        "\n",
        "        if defect == 'scratch':\n",
        "            # ìŠ¤í¬ë˜ì¹˜: ê¸´ ì§ì„ \n",
        "            w, h = random.randint(80, 150), random.randint(3, 8)\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (40, 40, 40), -1)\n",
        "\n",
        "        elif defect == 'dent':\n",
        "            # ì°Œê·¸ëŸ¬ì§: ì›í˜•\n",
        "            r = random.randint(15, 35)\n",
        "            w, h = r*2, r*2\n",
        "            cv2.circle(img, (x+r, y+r), r, (100, 100, 100), -1)\n",
        "            cv2.circle(img, (x+r, y+r), r-3, (140, 140, 140), -1)\n",
        "\n",
        "        elif defect == 'stain':\n",
        "            # ì–¼ë£©: ë¶ˆê·œì¹™í•œ ì›\n",
        "            w, h = random.randint(40, 80), random.randint(40, 80)\n",
        "            cv2.ellipse(img, (x+w//2, y+h//2), (w//2, h//2), 0, 0, 360, (80, 70, 60), -1)\n",
        "\n",
        "        elif defect == 'crack':\n",
        "            # ê· ì—´: ì§€ê·¸ì¬ê·¸ ì„ \n",
        "            w, h = random.randint(60, 100), random.randint(40, 70)\n",
        "            pts = np.array([[x, y], [x+w//3, y+h//2], [x+2*w//3, y+h//4], [x+w, y+h]])\n",
        "            cv2.polylines(img, [pts], False, (30, 30, 30), 2)\n",
        "\n",
        "        # YOLO í˜•ì‹ ë¼ë²¨ (ì •ê·œí™”ëœ ì¢Œí‘œ)\n",
        "        x_center = (x + w/2) / img_size\n",
        "        y_center = (y + h/2) / img_size\n",
        "        w_norm = w / img_size\n",
        "        h_norm = h / img_size\n",
        "        labels.append([class_map[defect], x_center, y_center, w_norm, h_norm])\n",
        "\n",
        "    return img, labels\n",
        "\n",
        "# í•™ìŠµ/ê²€ì¦ ë°ì´í„° ìƒì„±\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "for split, n_images in [('train', 100), ('val', 20)]:\n",
        "    for i in range(n_images):\n",
        "        img, labels = create_defect_image()\n",
        "\n",
        "        # ì´ë¯¸ì§€ ì €ì¥\n",
        "        cv2.imwrite(f'yolo_data/images/{split}/{i:04d}.jpg', img)\n",
        "\n",
        "        # ë¼ë²¨ ì €ì¥\n",
        "        with open(f'yolo_data/labels/{split}/{i:04d}.txt', 'w') as f:\n",
        "            for label in labels:\n",
        "                f.write(' '.join(map(str, label)) + '\\n')\n",
        "\n",
        "print('âœ… YOLO í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ!')\n",
        "print(f'   - í•™ìŠµ ì´ë¯¸ì§€: {len(os.listdir(\"yolo_data/images/train\"))}ê°œ')\n",
        "print(f'   - ê²€ì¦ ì´ë¯¸ì§€: {len(os.listdir(\"yolo_data/images/val\"))}ê°œ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sbLhIaH9zA_"
      },
      "outputs": [],
      "source": [
        "# YOLO ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±\n",
        "data_yaml = {\n",
        "    'path': '/content/yolo_data',  # Colab ê²½ë¡œ\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'names': {\n",
        "        0: 'scratch',\n",
        "        1: 'dent',\n",
        "        2: 'stain',\n",
        "        3: 'crack'\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('yolo_data/data.yaml', 'w') as f:\n",
        "    yaml.dump(data_yaml, f)\n",
        "\n",
        "print('âœ… ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±: yolo_data/data.yaml')\n",
        "print('\\ní´ë˜ìŠ¤ ëª©ë¡:')\n",
        "for k, v in data_yaml['names'].items():\n",
        "    print(f'   {k}: {v}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_t6d6T39zA_"
      },
      "outputs": [],
      "source": [
        "# ìƒì„±ëœ ë°ì´í„° ì‹œê°í™”\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "class_names = ['scratch', 'dent', 'stain', 'crack']\n",
        "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]\n",
        "\n",
        "for idx, ax in enumerate(axes.flatten()):\n",
        "    img_path = f'yolo_data/images/train/{idx:04d}.jpg'\n",
        "    label_path = f'yolo_data/labels/train/{idx:04d}.txt'\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # ë¼ë²¨ ì½ê¸° ë° ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            cls_id = int(parts[0])\n",
        "            x_center, y_center, bw, bh = map(float, parts[1:])\n",
        "\n",
        "            # ì •ê·œí™” ì¢Œí‘œë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜\n",
        "            x1 = int((x_center - bw/2) * w)\n",
        "            y1 = int((y_center - bh/2) * h)\n",
        "            x2 = int((x_center + bw/2) * w)\n",
        "            y2 = int((y_center + bh/2) * h)\n",
        "\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), colors[cls_id], 2)\n",
        "            cv2.putText(img, class_names[cls_id], (x1, y1-5),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[cls_id], 2)\n",
        "\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f'Sample {idx+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('ê²°í•¨ íƒì§€ í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ (ë°”ìš´ë”© ë°•ìŠ¤ í¬í•¨)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKo2bsSR9zA_"
      },
      "source": [
        "## 4.3 YOLOv8 ëª¨ë¸ í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dltoz_GE9zA_"
      },
      "outputs": [],
      "source": [
        "# Step 10: YOLOv8 ëª¨ë¸ í•™ìŠµ\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ì‚¬ì „í•™ìŠµëœ YOLOv8n ëª¨ë¸ ë¡œë“œ (nano - ê°€ì¥ ì‘ì€ ëª¨ë¸)\n",
        "yolo_model = YOLO('yolov8n.pt')\n",
        "\n",
        "print('ğŸš€ YOLOv8 í•™ìŠµ ì‹œì‘!\\n')\n",
        "\n",
        "# í•™ìŠµ ì‹¤í–‰\n",
        "results = yolo_model.train(\n",
        "    data='yolo_data/data.yaml',\n",
        "    epochs=30,           # ì—í¬í¬ ìˆ˜\n",
        "    imgsz=640,           # ì´ë¯¸ì§€ í¬ê¸°\n",
        "    batch=16,            # ë°°ì¹˜ í¬ê¸°\n",
        "    patience=10,         # ì¡°ê¸° ì¢…ë£Œ patience\n",
        "    device=0 if torch.cuda.is_available() else 'cpu',\n",
        "    verbose=True,\n",
        "    plots=True           # í•™ìŠµ ê·¸ë˜í”„ ìƒì„±\n",
        ")\n",
        "\n",
        "print('\\nâœ… YOLOv8 í•™ìŠµ ì™„ë£Œ!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOhStzQd9zBA"
      },
      "outputs": [],
      "source": [
        "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™” (ìë™ ìƒì„±ëœ ê·¸ë˜í”„)\n",
        "from IPython.display import Image as IPImage, display\n",
        "import glob\n",
        "\n",
        "# ìµœì‹  í•™ìŠµ ê²°ê³¼ í´ë” ì°¾ê¸°\n",
        "train_dirs = sorted(glob.glob('runs/detect/train*'))\n",
        "if train_dirs:\n",
        "    latest_dir = train_dirs[-1]\n",
        "    print(f'ğŸ“Š í•™ìŠµ ê²°ê³¼ í´ë”: {latest_dir}')\n",
        "\n",
        "    # ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ\n",
        "    result_images = ['results.png', 'confusion_matrix.png', 'F1_curve.png', 'PR_curve.png']\n",
        "\n",
        "    for img_name in result_images:\n",
        "        img_path = f'{latest_dir}/{img_name}'\n",
        "        if os.path.exists(img_path):\n",
        "            print(f'\\nğŸ“ˆ {img_name}:')\n",
        "            display(IPImage(filename=img_path, width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp2IV0SD9zBA"
      },
      "source": [
        "## 4.4 YOLOv8 ëª¨ë¸ ê²€ì¦ ë° ì¶”ë¡ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHPNZmUI9zBA"
      },
      "outputs": [],
      "source": [
        "# Step 11: í•™ìŠµëœ ëª¨ë¸ë¡œ ê²€ì¦ ë°ì´í„° í‰ê°€\n",
        "# ìµœì  ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "best_model_path = f'{latest_dir}/weights/best.pt'\n",
        "trained_model = YOLO(best_model_path)\n",
        "\n",
        "# ê²€ì¦ ì‹¤í–‰\n",
        "val_results = trained_model.val(data='yolo_data/data.yaml')\n",
        "\n",
        "print('\\nğŸ“Š ê²€ì¦ ê²°ê³¼:')\n",
        "print(f'   mAP50: {val_results.box.map50:.4f}')\n",
        "print(f'   mAP50-95: {val_results.box.map:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lryLjuSN9zBA"
      },
      "outputs": [],
      "source": [
        "# Step 12: ìƒˆë¡œìš´ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ \n",
        "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±\n",
        "test_img, test_labels = create_defect_image()\n",
        "cv2.imwrite('test_defect.jpg', test_img)\n",
        "\n",
        "# ì¶”ë¡  ì‹¤í–‰\n",
        "results = trained_model.predict(\n",
        "    source='test_defect.jpg',\n",
        "    conf=0.25,           # ì‹ ë¢°ë„ ì„ê³„ê°’\n",
        "    iou=0.45,            # NMS IOU ì„ê³„ê°’\n",
        "    save=True,           # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥\n",
        "    save_txt=True        # ë¼ë²¨ ì €ì¥\n",
        ")\n",
        "\n",
        "print('âœ… ì¶”ë¡  ì™„ë£Œ!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meEZECXK9zBA"
      },
      "outputs": [],
      "source": [
        "# ì¶”ë¡  ê²°ê³¼ ì‹œê°í™”\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# ì›ë³¸ ì´ë¯¸ì§€\n",
        "original = cv2.imread('test_defect.jpg')\n",
        "original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
        "axes[0].imshow(original)\n",
        "axes[0].set_title('ì›ë³¸ ì´ë¯¸ì§€')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# íƒì§€ ê²°ê³¼\n",
        "result_img = results[0].plot()  # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€\n",
        "result_img = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
        "axes[1].imshow(result_img)\n",
        "axes[1].set_title('YOLOv8 íƒì§€ ê²°ê³¼')\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# íƒì§€ ê²°ê³¼ ìƒì„¸ ì •ë³´\n",
        "print('\\nğŸ“‹ íƒì§€ëœ ê²°í•¨:')\n",
        "class_names = ['scratch', 'dent', 'stain', 'crack']\n",
        "for box in results[0].boxes:\n",
        "    cls_id = int(box.cls[0])\n",
        "    conf = float(box.conf[0])\n",
        "    x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "    print(f'   - {class_names[cls_id]}: ì‹ ë¢°ë„ {conf:.2%}, ìœ„ì¹˜ ({x1:.0f}, {y1:.0f}) - ({x2:.0f}, {y2:.0f})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwssMjqs9zBA"
      },
      "source": [
        "## 4.5 ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF6ekgNI9zBA"
      },
      "outputs": [],
      "source": [
        "# Step 13: ë°°ì¹˜ ì¶”ë¡  ë° ì„±ëŠ¥ ì¸¡ì •\n",
        "import time\n",
        "\n",
        "# ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±\n",
        "!mkdir -p test_images\n",
        "n_test = 10\n",
        "\n",
        "for i in range(n_test):\n",
        "    img, _ = create_defect_image()\n",
        "    cv2.imwrite(f'test_images/test_{i:03d}.jpg', img)\n",
        "\n",
        "# ì¶”ë¡  ì‹œê°„ ì¸¡ì •\n",
        "start_time = time.time()\n",
        "batch_results = trained_model.predict(\n",
        "    source='test_images/',\n",
        "    conf=0.25,\n",
        "    save=False,\n",
        "    verbose=False\n",
        ")\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print('â±ï¸ ì¶”ë¡  ì„±ëŠ¥:')\n",
        "print(f'   ì´ ì´ë¯¸ì§€: {n_test}ê°œ')\n",
        "print(f'   ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ')\n",
        "print(f'   ì´ë¯¸ì§€ë‹¹ í‰ê· : {total_time/n_test*1000:.1f}ms')\n",
        "print(f'   FPS: {n_test/total_time:.1f}')\n",
        "\n",
        "# ê²°ê³¼ ìš”ì•½\n",
        "print('\\nğŸ“Š íƒì§€ ê²°ê³¼ ìš”ì•½:')\n",
        "defect_counts = {'scratch': 0, 'dent': 0, 'stain': 0, 'crack': 0}\n",
        "for result in batch_results:\n",
        "    for box in result.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        defect_counts[class_names[cls_id]] += 1\n",
        "\n",
        "for defect, count in defect_counts.items():\n",
        "    print(f'   {defect}: {count}ê°œ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK5TJYen9zBA"
      },
      "source": [
        "## 4.6 ëª¨ë¸ ë‚´ë³´ë‚´ê¸° (ONNX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTleT-TO9zBA"
      },
      "outputs": [],
      "source": [
        "# Step 14: ONNX í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°\n",
        "# Edge ë””ë°”ì´ìŠ¤ë‚˜ ë‹¤ë¥¸ í”Œë«í¼ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜\n",
        "\n",
        "trained_model.export(\n",
        "    format='onnx',\n",
        "    imgsz=640,\n",
        "    simplify=True,\n",
        "    dynamic=False\n",
        ")\n",
        "\n",
        "print('âœ… ONNX ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ!')\n",
        "print(f'   ì €ì¥ ìœ„ì¹˜: {best_model_path.replace(\".pt\", \".onnx\")}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3nChHwy9zBA"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ“Œ í•µì‹¬ ì •ë¦¬\n",
        "\n",
        "## ë¶„ë¥˜ ëª¨ë¸ (ResNet)\n",
        "1. **ì „ì´í•™ìŠµ:** ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ í™œìš©í•´ ì ì€ ë°ì´í„°ë¡œë„ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "2. **í˜¼ë™í–‰ë ¬:** TP, TN, FP, FNì„ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ ë‹¤ê°ë„ë¡œ í‰ê°€í•©ë‹ˆë‹¤.\n",
        "3. **ì„ê³„ê°’ ì¡°ì •:** ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì— ë§ê²Œ ê²€ì¶œ ë¯¼ê°ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ê°ì²´ íƒì§€ ëª¨ë¸ (YOLO)\n",
        "4. **YOLOv8:** ê²°í•¨ì˜ ìœ„ì¹˜ì™€ ì¢…ë¥˜ë¥¼ ë™ì‹œì— íƒì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "5. **mAP:** ê°ì²´ íƒì§€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•µì‹¬ ì§€í‘œì…ë‹ˆë‹¤.\n",
        "6. **ì‹¤ì‹œê°„ ì²˜ë¦¬:** YOLOëŠ” ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¡œ ë¼ì¸ ì ìš©ì— ì í•©í•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸš€ ë„ì „ ê³¼ì œ\n",
        "\n",
        "1. ë°ì´í„° ì¦ê°•(Data Augmentation)ì„ ì¶”ê°€í•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•´ ë³´ì„¸ìš”.\n",
        "2. YOLOv8s, YOLOv8m ë“± ë” í° ëª¨ë¸ë¡œ í•™ìŠµí•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•´ ë³´ì„¸ìš”.\n",
        "3. ì‹¤ì œ MVTec AD ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í…ŒìŠ¤íŠ¸í•´ ë³´ì„¸ìš”.\n",
        "4. YOLOv8-segë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ í•™ìŠµí•´ ë³´ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WYENTo-9zBA"
      },
      "outputs": [],
      "source": [
        "# [ë„ì „ ê³¼ì œ] ë°ì´í„° ì¦ê°• ì˜ˆì‹œ\n",
        "# YOLOv8ì€ ìë™ìœ¼ë¡œ ë°ì´í„° ì¦ê°•ì„ ì ìš©í•˜ì§€ë§Œ, ì¶”ê°€ ì„¤ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "# ì»¤ìŠ¤í…€ ë°ì´í„° ì¦ê°• ì„¤ì •\n",
        "augmentation_config = {\n",
        "    'hsv_h': 0.015,      # ìƒ‰ìƒ ë³€í™”\n",
        "    'hsv_s': 0.7,        # ì±„ë„ ë³€í™”\n",
        "    'hsv_v': 0.4,        # ëª…ë„ ë³€í™”\n",
        "    'degrees': 10,       # íšŒì „\n",
        "    'translate': 0.1,    # ì´ë™\n",
        "    'scale': 0.5,        # ìŠ¤ì¼€ì¼\n",
        "    'shear': 5,          # ê¸°ìš¸ì„\n",
        "    'flipud': 0.5,       # ìƒí•˜ ë°˜ì „\n",
        "    'fliplr': 0.5,       # ì¢Œìš° ë°˜ì „\n",
        "    'mosaic': 1.0,       # ëª¨ìì´í¬ ì¦ê°•\n",
        "    'mixup': 0.1         # ë¯¹ìŠ¤ì—… ì¦ê°•\n",
        "}\n",
        "\n",
        "print('ğŸ’¡ ë°ì´í„° ì¦ê°• ì„¤ì • ì˜ˆì‹œ:')\n",
        "for k, v in augmentation_config.items():\n",
        "    print(f'   {k}: {v}')\n",
        "print('\\nìœ„ ì„¤ì •ì„ yolo_model.train()ì— ì „ë‹¬í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJF4RiTC9zBA"
      },
      "outputs": [],
      "source": [
        "# ëª¨ë¸ ì €ì¥\n",
        "torch.save(model.state_dict(), 'classification_model.pth')\n",
        "print('âœ… ë¶„ë¥˜ ëª¨ë¸ ì €ì¥: classification_model.pth')\n",
        "print(f'âœ… YOLO ëª¨ë¸ ì €ì¥: {best_model_path}')\n",
        "print('\\nğŸ‰ ì‹¤ìŠµ 1 ì™„ë£Œ! ë‹¤ìŒ ì‹¤ìŠµìœ¼ë¡œ ë„˜ì–´ê°€ì„¸ìš”.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsdeSUwd9zBA"
      },
      "source": [
        "---\n",
        "\n",
        "# ğŸ” ë¶„ë¥˜ vs YOLO ë¹„êµ ìš”ì•½\n",
        "\n",
        "| í•­ëª© | ë¶„ë¥˜ (ResNet) | ê°ì²´ íƒì§€ (YOLO) |\n",
        "|------|---------------|------------------|\n",
        "| **ì¶œë ¥** | OK/NG ë¼ë²¨ | ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ |\n",
        "| **ì¥ì ** | ë‹¨ìˆœ, ë¹ ë¥¸ í•™ìŠµ | ê²°í•¨ ìœ„ì¹˜/ì¢…ë¥˜ íŠ¹ì • |\n",
        "| **ë‹¨ì ** | ìœ„ì¹˜ ì •ë³´ ì—†ìŒ | ë¼ë²¨ë§ ë¹„ìš© ë†’ìŒ |\n",
        "| **í•™ìŠµ ë°ì´í„°** | ì´ë¯¸ì§€ + ë¼ë²¨ | ì´ë¯¸ì§€ + ë°”ìš´ë”© ë°•ìŠ¤ |\n",
        "| **ì¶”ë¡  ì†ë„** | ~5ms | ~15ms |\n",
        "| **ì ìš© ì‚¬ë¡€** | ì „ì²´ ì–‘/ë¶ˆ íŒì • | ê²°í•¨ ìƒì„¸ ë¶„ì„ |\n",
        "\n",
        "**ğŸ’¡ ì‹¤ë¬´ íŒ:** ë‘ ëª¨ë¸ì„ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì…ë‹ˆë‹¤!\n",
        "1. **1ì°¨ ê²€ì‚¬**: ë¶„ë¥˜ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ OK/NG íŒì •\n",
        "2. **2ì°¨ ê²€ì‚¬**: NG íŒì •ëœ ì œí’ˆë§Œ YOLOë¡œ ê²°í•¨ ìƒì„¸ ë¶„ì„\n",
        "\n",
        "---\n",
        "\n",
        "**â¡ï¸ ë‹¤ìŒ ì‹¤ìŠµ: ì˜ˆì§€ë³´ì „ & ê³µì • ìµœì í™”**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}